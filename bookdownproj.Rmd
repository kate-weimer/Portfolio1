--- 
title: 'ESS580: Bookdown Portfolio'
author: "Kate Weimer"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---

# Description
This is a compilation of five homework assignments completed in Spring 2022 for ESS 580: Ecological Data Science. 

```

<!--chapter:end:index.Rmd-->


```{r}
library(tidyverse)
library(dataRetrieval)
library(dygraphs)
library(xts)
library(yaml)
```



# 1: Discharge Example

## Methods

The Poudre River at Lincoln Bridge is:

  - Downstream of only a little bit of urban stormwater

  - Near Odell Brewing CO
  
  - Near an open space area and the Poudre River Trail
  
  - **Downstream of many agricultural diversions**


## Site Description



![](https://waterdata.usgs.gov/nwisweb/local/state/co/text/pics/06752260big.jpg)


## Data Acquisition and Plotting tests

## Data Download


```{r downloader}

q <- readNWISdv(siteNumbers = '06752260',
                parameterCd = '00060',
                startDate = '2017-01-01',
                endDate = '2022-01-01') %>%
  rename(q = 'X_00060_00003')


```



## Static Data Plotter


```{r, warning = FALSE, fig.width = 8, fig.height = 5}

ggplot(q, aes(x = Date, y = q)) + 
  geom_line() + 
  ylab('Q (cfs)') + 
  ggtitle('Discharge in the Poudre River, Fort Collins')

```


## Interactive Data Plotter


```{r}

q_xts <- xts(q$q, order.by = q$Date)

```



## DyGraph example. 
```{r}

q_xts <- xts(q$q, order.by = q$Date)


dygraph(q_xts) %>%
  dyAxis("y", label = "Discharge (cfs)") %>% dyEvent("2017-5-27", "27 May", labelLoc = "top") %>% dyEvent("2018-5-28", "28 May", labelLoc = "top")%>% dyEvent("2019-6-09", "09 Jun", labelLoc = "top")%>% dyEvent("2020-6-01", "01 Jun", labelLoc = "top")%>% dyEvent("2021-5-23", "23 May", labelLoc = "top")
```

```{r}
q_xts <- xts(q$q, order.by = q$Date)
dygraph(q_xts) %>%dyOptions(drawPoints = TRUE, pointSize = 2)
```

## Poudre Paragraph

The Cache la Poudre, or "Poudre" River is located in the Front Range of Colorado's Rocky Mountains. The name comes from French trappers who hid their gunpowder near the river. The Arapahoe name for the river is _ho'oowu' heetou'_ , which means 'where a house is located,' according to [CU Boulder's Center for the Study of Indigenous Languages of the West](https://www.colorado.edu/center/csilw/language-archives/arapaho-word-lists/place-names). The Poudre River is a tributarty of the South Platte, which later joins the Platte River, which is a tributary of the Missouri River, which in turn feeds the [Mississippi River](https://en.wikipedia.org/wiki/Mississippi_River) and **flows into the Gulf of Mexico**. According to the [Coalition for the Poudre River Watershed](https://www.poudrewatershed.org/cache-la-poudre-watershed), the Poudre supports water supply for **over 330,000 residents and 151,547 acres of irrigated land**.


<!--chapter:end:01-MarkdownExamples.Rmd-->

---
title: "Snow Data Assignment: Web Scraping, Functions, and Iteration"
author: "Kate Weimer"
date: "2-10-2022"
output: html_document
---

```{r setup3, include=FALSE}
library(rvest)
library(tidyverse)
library(lubridate)
library(readxl)
library(rvest)

```

# 3: Webscraping and Iterations

## Assignment:

1. Extract the meteorological data URLs. Here we want you to use the `rvest` package to get the URLs for the `SASP forcing` and `SBSP_forcing` meteorological datasets.c

```{r, message = FALSE}
datapath = 'data/'
dir.create(datapath)

```


```{r}
site_url <- 'https://snowstudies.org/archived-data/'

#Read the web url
webpage <- read_html(site_url)

links <- webpage %>%
  html_nodes('a') %>%
  .[grepl('forcing',.)] %>%
  html_attr('href')

#Grab only the name of the file by splitting out on forward slashes
splits <- str_split_fixed(links,'/',8)

#Keep only the 8th column
dataset <- splits[,8] 

# view(dataset)

file_names <- paste0(datapath,dataset)

```


2. Download the meteorological data. Use the `download_file` and `str_split_fixed` commands to download the data and save it in your data folder. You can use a for loop or a map function. 

```{r, message = FALSE}
#generate a file list for where the data goes
file_names <- paste0('data/',dataset)

for(i in 1:2){
  download.file(links[i],destfile=file_names[i])
}

downloaded <- file.exists(file_names)

evaluate <- !all(downloaded)
```

3. Write a custom function to read in the data and append a site column to the data. 

```{r}

# this code grabs the variable names from the metadata pdf file
library(pdftools)
headers <- pdf_text('https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf') %>%
  readr::read_lines(.) %>%
  trimws(.) %>%
  str_split_fixed(.,'\\.',2) %>%
  .[,2] %>%
  .[1:26] %>%
  str_trim(side = "left")

```


```{r}
read_in_weatherdata <- function(file){
name = str_split_fixed(file,'_',3)[,2] 
   df <- read.delim(file, header = F, sep = "", skip =4) %>%  mutate(site = name)
return(df)
}

```


4. Use the `map` function to read in both meteorological files. Display a summary of your tibble.
```{r, message= FALSE}
setwd("~/Spring 2022/ESS580/3_snow_functions_iteration/data")
weather_data_full <- map_dfr(dataset, read_in_weatherdata) 

weather_data_full <- select(weather_data_full, V1, V2, V10, site)%>% rename(Year = V1, Month = V2, temp = V10)

summary(weather_data_full)

```

5. Make a line plot of mean temp by year by site (using the `air temp [K]` variable). Is there anything suspicious in the plot? Adjust your filtering if needed.

```{r, warning= FALSE, message= FALSE}
weather_data_yearlymean <- weather_data_full %>% group_by(Year,site) %>% filter(Year != 2003, Year != 2011) %>% summarize(meantemp = mean(temp))
```


```{r}
ggplot(weather_data_yearlymean, aes(x = Year, y = meantemp, color = site )) +
  geom_line() +
  labs( x = "Year", y = "Mean Temperature (K)")
```

The dataset only included parts of 2003 and 2011, which skewed the yearly average for both years. 

6. Write a function that makes line plots of monthly average temperature at each site for a given year. Use a for loop to make these plots for 2005 to 2010. Are monthly average temperatures at the Senator Beck Study Plot ever warmer than the Snow Angel Study Plot?
Hint: https://ggplot2.tidyverse.org/reference/print.ggplot.html


```{r}
# create a function
yearly_plotter <- function(df, year){
  
  monthly_mean <- df  %>% 
    group_by(Year, Month, site) %>% 
    summarize(meantemp = mean(temp)) %>% filter(year == Year) 
  
   
  figure <- ggplot(monthly_mean, aes(x = Month, y = meantemp, color = site )) +
  geom_line() +
  labs( x = "Month", y = "Mean Temperature (K)") 

  
  print(figure)
}
```

```{r, message= FALSE}
# run the function in a for loop

x <- c(2005, 2006, 2007, 2008, 2009, 2010)

for(year in x){(yearly_plotter(weather_data_full, year))}
```


<!--chapter:end:03-Webscraping.Rmd-->

---
title: "LAGOS Spatial Analysis"
author: "Kate Weimer"
date: "23 February 2022"
output: html_document
editor_options: 
  chunk_output_type: console
---



```{r setup4, include=FALSE}
library(tidyverse) # Tidy packages
library(sf) #Spatial package that can read and create shapefiles 
library(mapview) #Interactive maps
library(LAGOSNE) #Lots and lots of clean lake data
library(USAboundaries) #USA states and counties
```


# 4: LAGOS Analysis


## Loading in data


### First download and then specifically grab the locus (or site lat longs)

```{r data-read, warning=FALSE}
# #Lagos download script
#LAGOSNE::lagosne_get(dest_folder = LAGOSNE:::lagos_path())
#Load in lagos
lagos <- lagosne_load()

#Grab the lake centroid info
lake_centers <- lagos$locus

```



### Convert to spatial data
```{r}
#Look at the column names
#names(lake_centers)

#Look at the structure
#str(lake_centers)

#View the full dataset
#View(lake_centers %>% slice(1:100))

spatial_lakes <- st_as_sf(lake_centers,coords=c('nhd_long','nhd_lat'),
                          crs=4326) %>%
  st_transform(2163)

#Subset for plotting
subset_spatial <- spatial_lakes %>%
  slice(1:100) 

subset_baser <- spatial_lakes[1:100,]

#Dynamic mapviewer
mapview(subset_spatial)

```


### Subset to only Minnesota

```{r}
states <- us_states()

#Plot all the states to check if they loaded
#mapview(states)
minnesota <- states %>%
  filter(name == 'Minnesota') %>%
  st_transform(2163)

#Subset lakes based on spatial position
minnesota_lakes <- spatial_lakes[minnesota,]

#Plotting the first 1000 lakes
minnesota_lakes %>%
  arrange(-lake_area_ha) %>%
    slice(1:1000) %>%
  mapview(.,zcol = 'lake_area_ha')
```



## 1) Show a map outline of Iowa and Illinois (similar to Minnesota map upstream)

```{r}
IA_IL <- states %>%
  filter(name == "Iowa" | name == "Illinois") %>%
  st_transform(2163)


mapview(IA_IL)
```



## 2) Subset LAGOS data to these sites, how many sites are in Illinois and Iowa combined? How does this compare to Minnesota?

```{r}
IA_IL_lakes <- spatial_lakes[IA_IL,]
count(IA_IL_lakes)
```

There are 16466 sites in Iowa and Illinois combined, which is a little more that half the sites in Minnesota alone. 


## 3) What is the distribution of lake size in Iowa vs. Minnesota?

- Here I want to see a histogram plot with lake size on x-axis and frequency on 
y axis (check out geom_histogram)


```{r}
Q3 <- spatial_lakes %>% filter(state_zoneid == "State_14" | state_zoneid == "State_13") %>% 
  mutate(state = ifelse(state_zoneid == "State_14", paste("Minnesota"), paste("Iowa")))

ggplot(Q3, aes(lake_area_ha))+
  geom_histogram(bins = 4) +
  # scale_x_continuous(breaks = seq(0, 130000, 4))
  facet_wrap(~state) 
  
 max(Q3$lake_area_ha)
```

The majority of lakes in both states are under 25,000 acres. Minnesota has many more lakes.  

## 4) Make an interactive plot of lakes in Iowa and Illinois and color them by lake area in hectares

```{r}
IA_IL_lakes %>%
  arrange(-lake_area_ha) %>%
  mapview(.,zcol = 'lake_area_ha')
```


## 5) What other data sources might we use to understand how reservoirs and natural lakes vary in size in these three states? 

Lake volume could be a more meaningful metric than lake area for people interested in available water for agriculture or other purposes. 

<!--chapter:end:04-Geospatial.Rmd-->

---
title: "Weather and Corn Yield Regressions"
author: "Kate Weimer"
date: "3/4/2022"
output: html_document
---

```{r setup5, include=FALSE}

library(tidyverse)
library(R.matlab)
library(rnassqs)
```

# 5: Weather and Crop Regressions

### Load the PRISM daily maximum temperatures

```{r tmax data}

# daily max temperature
# dimensions: counties x days x years
prism <- readMat("prismiowa.mat")

# look at county #1
t_1981_c1 <- prism$tmaxdaily.iowa[1,,1]
t_1981_c1[366]
plot(1:366, t_1981_c1, type = "l")

ggplot() +
  geom_line(mapping = aes(x=1:366, y = t_1981_c1)) +
  theme_bw() +
  xlab("day of year") +
  ylab("daily maximum temperature (°C)") +
  ggtitle("Daily Maximum Temperature, Iowa County #1")


```
```{r tidying up}

# assign dimension names to tmax matrix
dimnames(prism$tmaxdaily.iowa) <- list(prism$COUNTYFP, 1:366, prism$years)

# converted 3d matrix into a data frame
tmaxdf <- as.data.frame.table(prism$tmaxdaily.iowa)

# relabel the columns
colnames(tmaxdf) <- c("countyfp","doy","year","tmax")
tmaxdf <- tibble(tmaxdf)

```

## Temperature trends

### Summer temperature trends: Winneshiek County

```{r temp trends}

tmaxdf$doy <- as.numeric(tmaxdf$doy)
tmaxdf$year <- as.numeric(as.character(tmaxdf$year))

winnesummer <- tmaxdf %>%
  filter(countyfp==191 & doy >= 152 & doy <= 243) %>%
  group_by(year) %>%
  summarize(meantmax = mean(tmax))

ggplot(winnesummer, mapping = aes(x = year, y = meantmax)) +
  geom_point() +
  theme_bw() +
  labs(x = "year", y = "Tmax (°C)") +
  geom_smooth(method = lm)

lm_summertmax <- lm(meantmax ~ year, winnesummer)
summary(lm_summertmax)

```

### Winter Temperatures - Winneshiek County

```{r winter temps}

winnewinter <- tmaxdf %>%
  filter(countyfp==191 & (doy <= 59 | doy >= 335) & !is.na(tmax)) %>%
  group_by(year) %>%
  summarize(meantmax = mean(tmax))

ggplot(winnewinter, mapping = aes(x = year, y = meantmax)) +
  geom_point() +
  theme_bw() +
  labs(x = "year", y = "Tmax (°C)") +
  geom_smooth(method = lm)

lm_wintertmax <- lm(meantmax ~ year, winnewinter)
summary(lm_wintertmax)

```

### Multiple regression -- Quadratic time trend

```{r quadratic temp trend}

winnewinter$yearsq <- winnewinter$year^2

lm_wintertmaxquad <- lm(meantmax ~ year + yearsq, winnewinter)
summary(lm_wintertmaxquad)
winnewinter$fitted <- lm_wintertmaxquad$fitted.values

ggplot(winnewinter) +
  geom_point(mapping = aes(x = year, y = meantmax)) +
  geom_line(mapping = aes(x = year, y = fitted)) +
  theme_bw() +
  labs(x = "year", y = "tmax")

```

### Download NASS corn yield data

```{r yield download, include= FALSE}

# set our API key with NASS
nassqs_auth(key = "F910F0DC-5753-32D7-8A19-A351D49F87D9")

# parameters to query on 
params <- list(commodity_desc = "CORN", util_practice_desc = "GRAIN", prodn_practice_desc = "ALL PRODUCTION PRACTICES", year__GE = 1981, state_alpha = "IA")

# download
cornyieldsall <- nassqs_yields(params)

cornyieldsall$county_ansi <- as.numeric(cornyieldsall$county_ansi)
cornyieldsall$yield <- as.numeric(cornyieldsall$Value)

# clean and filter this dataset
cornyields <- select(cornyieldsall, county_ansi, county_name, yield, year) %>%
  filter(!is.na(county_ansi) & !is.na(yield))
cornyields <- tibble(cornyields)

```

## Assignment

### Question 1a: Extract Winneshiek County corn yields, fit a linear time trend, make a plot. Is there a significant time trend?

```{r}
winniecorn <- cornyields %>% filter( county_name == "WINNESHIEK") 

ggplot(winniecorn, mapping = aes(x = year, y = yield)) +
  geom_point() +
  theme_bw() +
  labs(x = "year", y = "yield") +
  geom_smooth(method = lm)
```

There is a positive trend between year and yield. 

### Question 1b: Fit a quadratic time trend (i.e., year + year^2) and make a plot. Is there evidence for slowing yield growth? 

```{r}
winniecorn$yearsq <- winniecorn$year^2

lm_cornyield <- lm(yield ~ year + yearsq, winniecorn)
summary(lm_cornyield)
winniecorn$fitted <- lm_cornyield$fitted.values

ggplot(winniecorn) +
  geom_point(mapping = aes(x = year, y = yield)) +
  geom_line(mapping = aes(x = year, y = fitted)) +
  theme_bw() +
  labs(x = "year", y = "yield")
```

There is not evidence for slowing yield growth. 

### Question 2 -- Time Series: Let's analyze the relationship between temperature and yields for the Winneshiek County time series. Use data on yield and summer avg Tmax. Is adding year or Tmax^2 to your model helpful? Make a plot and interpret the results.



```{r}
winniecorn2 <- right_join(winniecorn, winnesummer, by = "year")

ggplot(winniecorn2, mapping = aes(x = meantmax, y = yield)) +
  geom_point() +
  theme_bw() +
  labs(x = "temp", y = "yield") +
  geom_smooth(method = lm)
```
```{r}

lm_q2 <- lm(yield ~ meantmax + year, data = winniecorn2)
summary(lm_q2)
winniecorn2$fitted <- lm_q2$fitted.values

ggplot(winniecorn2) +
  geom_point(mapping = aes(x = meantmax, y = yield)) +
  geom_smooth(mapping = aes(x = meantmax, y = fitted)) +
  theme_bw() +
  labs(x = "temp", y = "yield")

```

### Question 3 -- Cross-Section: Analyze the relationship between temperature and yield across all counties in 2018. Is there a relationship? Interpret the results.

In 2018, there is a negative relationship (slope = -4.216) between temperature and yield across counties. 
```{r}
cornyields$countyfp <- as.factor(cornyields$county_ansi)
cornyields2018 <- cornyields %>% filter(year== "2018")

q3 <- tmaxdf %>% filter(year == "2018" & doy >= 152 & doy <= 243) %>% 
  group_by(countyfp) %>% summarize(meantmax = mean(tmax)) %>% 
  left_join(cornyields2018, by = 'countyfp') %>% filter(!is.na(yield))

lm_2018 <- lm(yield ~ meantmax, data = q3)
summary(lm_2018)

ggplot(q3, aes(x = meantmax, y = yield)) +
  geom_point() +
  theme_bw() +
  geom_smooth(method = lm)+
  labs(x = "temp", y = "yield", title = "2018")

```

### Question 4 -- Panel: One way to leverage multiple time series is to group all data into what is called a "panel" regression. Convert the county ID code ("countyfp" or "county_ansi") into factor using as.factor, then include this variable in a regression using all counties' yield and summer temperature data. How does the significance of your temperature coefficients (Tmax, Tmax^2) change? Make a plot comparing actual and fitted yields and interpret the results of your model.

In this model, year is the only significant predictor of yield (p < 2e-16).

```{r}
q4 <-  tmaxdf %>% filter( doy >= 152 & doy <= 243) %>% 
  group_by(countyfp) %>% summarize(meantmax = mean(tmax)) %>% 
  left_join(cornyields, by = 'countyfp') %>% filter(!is.na(yield)) %>%
  mutate(tmaxsq = (meantmax)^2)

lm_q4 <- lm(yield ~ meantmax + tmaxsq + year + countyfp, data = q4)
summary(lm_q4)

```

### Question 5 -- Soybeans: Download NASS data on soybean yields and explore either a time series relationship for a given county, the cross-sectional relationship for a given year, or a panel across all counties and years.

There is a positive relationship between year and soybean yield in Madison County between 1981 and 2021. 

```{r, include= FALSE}
# set our API key with NASS
nassqs_auth(key = "F910F0DC-5753-32D7-8A19-A351D49F87D9")

# parameters to query on 
params <- list(commodity_desc = "SOYBEANS", statisticcat_desc="YIELD", prodn_practice_desc = "ALL PRODUCTION PRACTICES", year__GE = 1981, state_alpha = "IA")

# download
soyyieldsall <- nassqs_yields(params)

soyyieldsall$county_ansi <- as.numeric(soyyieldsall$county_ansi)
soyyieldsall$yield <- as.numeric(soyyieldsall$Value)

# clean and filter this dataset
soyyields <- select(soyyieldsall, county_ansi, county_name, yield, year) %>%
  filter(!is.na(county_ansi) & !is.na(yield))
soyyields <- tibble(soyyields)
```
```{r}
madisonsoy<- soyyields %>% filter( county_name == "MADISON") 

ggplot(madisonsoy, mapping = aes(x = year, y = yield)) +
  geom_point() +
  theme_bw() +
  labs(x = "year", y = "yield") +
  geom_smooth(method = lm)
```


### Bonus: Find a package to make a county map of Iowa displaying some sort of information about yields or weather. Interpret your map.

### Bonus #2: Challenge question - map trends in corn yields by county across Iowa. Interpret your map.

<!--chapter:end:05-CornRegressions.rmd-->

